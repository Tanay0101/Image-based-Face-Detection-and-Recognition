{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, Concatenate, Input, GlobalAveragePooling2D, Dropout, Subtract, Lambda\n",
    "from keras import Model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 5, 5, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 5, 5, 448)    1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 5, 5, 448)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 5, 5, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 5, 5, 384)    1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 5, 5, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 5, 5, 384)    1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 5, 5, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 5, 5, 384)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 5, 5, 384)    442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 5, 5, 384)    442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 5, 5, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 5, 5, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 5, 5, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 5, 5, 384)    1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 5, 5, 384)    1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 5, 5, 384)    1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 5, 5, 192)    393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 5, 5, 320)    960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 5, 5, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 5, 5, 384)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 5, 5, 384)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 5, 5, 384)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 5, 5, 192)    576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 5, 5, 320)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 5, 5, 768)    0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 5, 5, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 5, 5, 192)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 5, 5, 2048)   0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inception_model =  keras.applications.InceptionV3(include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape= (224, 224, 3))\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 111, 111, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 111, 111, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 111, 111, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 109, 109, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 109, 109, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 109, 109, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 109, 109, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 109, 109, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 109, 109, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 54, 54, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 54, 54, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 54, 54, 80)   240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 54, 54, 80)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 52, 52, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 52, 52, 192)  576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 52, 52, 192)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 25, 25, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 25, 25, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 25, 25, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 25, 25, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 25, 25, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 25, 25, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 25, 25, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 25, 25, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 25, 25, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 25, 25, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 25, 25, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 25, 25, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 25, 25, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 25, 25, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 25, 25, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 25, 25, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 25, 25, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 25, 25, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 25, 25, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 25, 25, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 25, 25, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 25, 25, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 25, 25, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 25, 25, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 25, 25, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 25, 25, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 25, 25, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 25, 25, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 25, 25, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 25, 25, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 25, 25, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 25, 25, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 25, 25, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 25, 25, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 25, 25, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 25, 25, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 25, 25, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 25, 25, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 25, 25, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 25, 25, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 25, 25, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 25, 25, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 25, 25, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 25, 25, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 25, 25, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 25, 25, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 25, 25, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 25, 25, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 25, 25, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 25, 25, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 25, 25, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 25, 25, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 25, 25, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 25, 25, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 25, 25, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 25, 25, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 25, 25, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 25, 25, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 25, 25, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 25, 25, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 25, 25, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 25, 25, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 25, 25, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 25, 25, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 25, 25, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 25, 25, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 25, 25, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 25, 25, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 25, 25, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 25, 25, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 25, 25, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 25, 25, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 25, 25, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 12, 12, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 12, 12, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 12, 12, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 12, 12, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 12, 12, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 12, 12, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 12, 12, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 12, 12, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 12, 12, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 12, 12, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 12, 12, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 12, 12, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 12, 12, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 12, 12, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 12, 12, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 12, 12, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 12, 12, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 12, 12, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 12, 12, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 12, 12, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 12, 12, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 12, 12, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 12, 12, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 12, 12, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 12, 12, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 12, 12, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 12, 12, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 12, 12, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 12, 12, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 12, 12, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 12, 12, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 12, 12, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 12, 12, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 12, 12, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 12, 12, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 12, 12, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 12, 12, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 12, 12, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 12, 12, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 12, 12, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 12, 12, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 12, 12, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 12, 12, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 12, 12, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 12, 12, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 12, 12, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 12, 12, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 12, 12, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 12, 12, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 12, 12, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 12, 12, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 12, 12, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 12, 12, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 12, 12, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 12, 12, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 12, 12, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 12, 12, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 12, 12, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 12, 12, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 12, 12, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 12, 12, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 12, 12, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 12, 12, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 12, 12, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 12, 12, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 12, 12, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 12, 12, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 12, 12, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 12, 12, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 12, 12, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 12, 12, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 12, 12, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 12, 12, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 12, 12, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 12, 12, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 12, 12, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 12, 12, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 12, 12, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 12, 12, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 12, 12, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 12, 12, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 12, 12, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 12, 12, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 12, 12, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 12, 12, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 12, 12, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 12, 12, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 12, 12, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 12, 12, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 12, 12, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 12, 12, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 12, 12, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 12, 12, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 12, 12, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 12, 12, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 12, 12, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 12, 12, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 12, 12, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 12, 12, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 12, 12, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 12, 12, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 12, 12, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 12, 12, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 12, 12, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 12, 12, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 12, 12, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 12, 12, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 12, 12, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 12, 12, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 12, 12, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 12, 12, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 12, 12, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 12, 12, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 12, 12, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 12, 12, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 12, 12, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 12, 12, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 12, 12, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 12, 12, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 12, 12, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 12, 12, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 12, 12, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 12, 12, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 12, 12, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 12, 12, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 12, 12, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 12, 12, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 12, 12, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 12, 12, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 12, 12, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 12, 12, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 12, 12, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 12, 12, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 12, 12, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 12, 12, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 12, 12, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 12, 12, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 12, 12, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 12, 12, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 5, 5, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 5, 5, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 5, 5, 320)    960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 5, 5, 192)    576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 5, 5, 320)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 5, 5, 192)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 5, 5, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 5, 5, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 5, 5, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 5, 5, 448)    1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 5, 5, 448)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 5, 5, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 5, 5, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 5, 5, 384)    1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 5, 5, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 5, 5, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 5, 5, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 5, 5, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 5, 5, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 5, 5, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 5, 5, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 5, 5, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 5, 5, 384)    1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 5, 5, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 5, 5, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 5, 5, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 5, 5, 320)    960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 5, 5, 384)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 5, 5, 384)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 5, 5, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 5, 5, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 5, 5, 192)    576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 5, 5, 320)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 5, 5, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 5, 5, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 5, 5, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 15,984,992\n",
      "Trainable params: 262,272\n",
      "Non-trainable params: 15,722,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "densor1 = Dense(128, activation = 'relu')\n",
    "\n",
    "for layer in inception_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "last_layer = inception_model.get_layer('mixed9')\n",
    "last_output = last_layer.output\n",
    "x = GlobalAveragePooling2D()(last_output)\n",
    "x = Dropout(0.2)(x)\n",
    "x = densor1(x)\n",
    "\n",
    "\n",
    "pretrained_model = Model(inputs = inception_model.input, outputs = x)\n",
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_model():\n",
    "    input_A = Input(shape = (224, 224, 3))\n",
    "    input_B = Input(shape = (224, 224, 3))\n",
    "    \n",
    "    A_x = pretrained_model(input_A)\n",
    "    B_x = pretrained_model(input_B)\n",
    "    \n",
    "    x = Subtract()([A_x, B_x])\n",
    "    x = Lambda(lambda y:abs(y))(x)\n",
    "    x = Dense(1, activation = 'sigmoid')(x)\n",
    "    model = Model(inputs = [input_A, input_B], outputs = x)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "model_1 (Model)                 (None, 128)          15984992    input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 128)          0           model_1[1][0]                    \n",
      "                                                                 model_1[2][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 128)          0           subtract_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 15,985,121\n",
      "Trainable params: 262,401\n",
      "Non-trainable params: 15,722,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = full_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2200, 224, 224, 3)\n",
      "(2200, 224, 224, 3)\n",
      "(2200, 1)\n"
     ]
    }
   ],
   "source": [
    "inputA, inputB, y = load_data(r'C:\\Users\\Dev\\Desktop\\Ongoing_projects\\Face_Recognition\\Data\\pairsDevTrain.txt')\n",
    "print(inputA.shape)\n",
    "print(inputB.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from random import shuffle\n",
    "\n",
    "ind_list = [i for i in range(inputA.shape[0])]\n",
    "shuffle(ind_list)\n",
    "inputA  = inputA[ind_list, :,:,:]\n",
    "inputB = inputB[ind_list, :,:,:]\n",
    "y = y[ind_list, :]\n",
    "inputA = inputA/255\n",
    "inputB = inputB/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, 'my_logs')\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"model2.h5\",save_best_only = True)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 100,restore_best_weights= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = 'adam', metrics=[ tf.keras.metrics.BinaryAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1980 samples, validate on 220 samples\n",
      "Epoch 1/150\n",
      "1980/1980 [==============================] - 65s 33ms/step - loss: 0.6980 - binary_accuracy: 0.4965 - val_loss: 0.6905 - val_binary_accuracy: 0.5106\n",
      "Epoch 2/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.6536 - binary_accuracy: 0.5639 - val_loss: 0.6866 - val_binary_accuracy: 0.5907\n",
      "Epoch 3/150\n",
      "1980/1980 [==============================] - 38s 19ms/step - loss: 0.6025 - binary_accuracy: 0.6222 - val_loss: 0.6813 - val_binary_accuracy: 0.6380\n",
      "Epoch 4/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.5340 - binary_accuracy: 0.6620 - val_loss: 0.6735 - val_binary_accuracy: 0.6808\n",
      "Epoch 5/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.4476 - binary_accuracy: 0.7019 - val_loss: 0.6685 - val_binary_accuracy: 0.7169\n",
      "Epoch 6/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.3739 - binary_accuracy: 0.7334 - val_loss: 0.6654 - val_binary_accuracy: 0.7448\n",
      "Epoch 7/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.3047 - binary_accuracy: 0.7577 - val_loss: 0.6782 - val_binary_accuracy: 0.7680\n",
      "Epoch 8/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.2340 - binary_accuracy: 0.7798 - val_loss: 0.6714 - val_binary_accuracy: 0.7891\n",
      "Epoch 9/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.1863 - binary_accuracy: 0.7985 - val_loss: 0.6862 - val_binary_accuracy: 0.8061\n",
      "Epoch 10/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.1532 - binary_accuracy: 0.8143 - val_loss: 0.6994 - val_binary_accuracy: 0.8209\n",
      "Epoch 11/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.1167 - binary_accuracy: 0.8278 - val_loss: 0.7055 - val_binary_accuracy: 0.8334\n",
      "Epoch 12/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.1036 - binary_accuracy: 0.8393 - val_loss: 0.7190 - val_binary_accuracy: 0.8437\n",
      "Epoch 13/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0814 - binary_accuracy: 0.8486 - val_loss: 0.7372 - val_binary_accuracy: 0.8526\n",
      "Epoch 14/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0704 - binary_accuracy: 0.8568 - val_loss: 0.7397 - val_binary_accuracy: 0.8602\n",
      "Epoch 15/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0635 - binary_accuracy: 0.8639 - val_loss: 0.7474 - val_binary_accuracy: 0.8668\n",
      "Epoch 16/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0581 - binary_accuracy: 0.8701 - val_loss: 0.7463 - val_binary_accuracy: 0.8727\n",
      "Epoch 17/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0501 - binary_accuracy: 0.8756 - val_loss: 0.7495 - val_binary_accuracy: 0.8780\n",
      "Epoch 18/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0389 - binary_accuracy: 0.8806 - val_loss: 0.7591 - val_binary_accuracy: 0.8827\n",
      "Epoch 19/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0378 - binary_accuracy: 0.8850 - val_loss: 0.7745 - val_binary_accuracy: 0.8869\n",
      "Epoch 20/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0370 - binary_accuracy: 0.8889 - val_loss: 0.7822 - val_binary_accuracy: 0.8906\n",
      "Epoch 21/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0335 - binary_accuracy: 0.8926 - val_loss: 0.7950 - val_binary_accuracy: 0.8941\n",
      "Epoch 22/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0277 - binary_accuracy: 0.8959 - val_loss: 0.7994 - val_binary_accuracy: 0.8973\n",
      "Epoch 23/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0292 - binary_accuracy: 0.8988 - val_loss: 0.7969 - val_binary_accuracy: 0.9000\n",
      "Epoch 24/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0265 - binary_accuracy: 0.9014 - val_loss: 0.8116 - val_binary_accuracy: 0.9026\n",
      "Epoch 25/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0217 - binary_accuracy: 0.9040 - val_loss: 0.8170 - val_binary_accuracy: 0.9050\n",
      "Epoch 26/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0189 - binary_accuracy: 0.9063 - val_loss: 0.8422 - val_binary_accuracy: 0.9073\n",
      "Epoch 27/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0186 - binary_accuracy: 0.9085 - val_loss: 0.8616 - val_binary_accuracy: 0.9094\n",
      "Epoch 28/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0195 - binary_accuracy: 0.9105 - val_loss: 0.8679 - val_binary_accuracy: 0.9112\n",
      "Epoch 29/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0184 - binary_accuracy: 0.9122 - val_loss: 0.8805 - val_binary_accuracy: 0.9129\n",
      "Epoch 30/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0186 - binary_accuracy: 0.9138 - val_loss: 0.8965 - val_binary_accuracy: 0.9144\n",
      "Epoch 31/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0172 - binary_accuracy: 0.9153 - val_loss: 0.8979 - val_binary_accuracy: 0.9159\n",
      "Epoch 32/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0159 - binary_accuracy: 0.9168 - val_loss: 0.9003 - val_binary_accuracy: 0.9173\n",
      "Epoch 33/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0123 - binary_accuracy: 0.9181 - val_loss: 0.9105 - val_binary_accuracy: 0.9186\n",
      "Epoch 34/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0123 - binary_accuracy: 0.9194 - val_loss: 0.9266 - val_binary_accuracy: 0.9199\n",
      "Epoch 35/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0117 - binary_accuracy: 0.9206 - val_loss: 0.9175 - val_binary_accuracy: 0.9211\n",
      "Epoch 36/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0111 - binary_accuracy: 0.9219 - val_loss: 0.9141 - val_binary_accuracy: 0.9223\n",
      "Epoch 37/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0100 - binary_accuracy: 0.9230 - val_loss: 0.9213 - val_binary_accuracy: 0.9234\n",
      "Epoch 38/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0098 - binary_accuracy: 0.9241 - val_loss: 0.9078 - val_binary_accuracy: 0.9245\n",
      "Epoch 39/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0095 - binary_accuracy: 0.9252 - val_loss: 0.9397 - val_binary_accuracy: 0.9255\n",
      "Epoch 40/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0094 - binary_accuracy: 0.9261 - val_loss: 0.9491 - val_binary_accuracy: 0.9265\n",
      "Epoch 41/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0096 - binary_accuracy: 0.9270 - val_loss: 0.9348 - val_binary_accuracy: 0.9273\n",
      "Epoch 42/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0090 - binary_accuracy: 0.9279 - val_loss: 0.9360 - val_binary_accuracy: 0.9282\n",
      "Epoch 43/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0065 - binary_accuracy: 0.9287 - val_loss: 0.9344 - val_binary_accuracy: 0.9290\n",
      "Epoch 44/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0096 - binary_accuracy: 0.9295 - val_loss: 0.9375 - val_binary_accuracy: 0.9298\n",
      "Epoch 45/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0091 - binary_accuracy: 0.9303 - val_loss: 0.9445 - val_binary_accuracy: 0.9306\n",
      "Epoch 46/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0081 - binary_accuracy: 0.9310 - val_loss: 0.9415 - val_binary_accuracy: 0.9312\n",
      "Epoch 47/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0080 - binary_accuracy: 0.9317 - val_loss: 0.9538 - val_binary_accuracy: 0.9319\n",
      "Epoch 48/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0061 - binary_accuracy: 0.9323 - val_loss: 0.9565 - val_binary_accuracy: 0.9325\n",
      "Epoch 49/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0063 - binary_accuracy: 0.9329 - val_loss: 0.9779 - val_binary_accuracy: 0.9332\n",
      "Epoch 50/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0082 - binary_accuracy: 0.9336 - val_loss: 0.9469 - val_binary_accuracy: 0.9337\n",
      "Epoch 51/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0092 - binary_accuracy: 0.9341 - val_loss: 0.9418 - val_binary_accuracy: 0.9343\n",
      "Epoch 52/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0079 - binary_accuracy: 0.9347 - val_loss: 0.9644 - val_binary_accuracy: 0.9349\n",
      "Epoch 53/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0071 - binary_accuracy: 0.9352 - val_loss: 0.9508 - val_binary_accuracy: 0.9354\n",
      "Epoch 54/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0104 - binary_accuracy: 0.9357 - val_loss: 0.9783 - val_binary_accuracy: 0.9358\n",
      "Epoch 55/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0089 - binary_accuracy: 0.9362 - val_loss: 0.9673 - val_binary_accuracy: 0.9363\n",
      "Epoch 56/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0075 - binary_accuracy: 0.9366 - val_loss: 0.9845 - val_binary_accuracy: 0.9368\n",
      "Epoch 57/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0078 - binary_accuracy: 0.9371 - val_loss: 0.9822 - val_binary_accuracy: 0.9372\n",
      "Epoch 58/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0062 - binary_accuracy: 0.9375 - val_loss: 0.9993 - val_binary_accuracy: 0.9376\n",
      "Epoch 59/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0076 - binary_accuracy: 0.9379 - val_loss: 0.9681 - val_binary_accuracy: 0.9380\n",
      "Epoch 60/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0068 - binary_accuracy: 0.9383 - val_loss: 0.9366 - val_binary_accuracy: 0.9384\n",
      "Epoch 61/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0055 - binary_accuracy: 0.9388 - val_loss: 0.9300 - val_binary_accuracy: 0.9389\n",
      "Epoch 62/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0082 - binary_accuracy: 0.9392 - val_loss: 0.9758 - val_binary_accuracy: 0.9393\n",
      "Epoch 63/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0087 - binary_accuracy: 0.9396 - val_loss: 0.9704 - val_binary_accuracy: 0.9397\n",
      "Epoch 64/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0084 - binary_accuracy: 0.9400 - val_loss: 0.9576 - val_binary_accuracy: 0.9401\n",
      "Epoch 65/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0082 - binary_accuracy: 0.9403 - val_loss: 0.9945 - val_binary_accuracy: 0.9404\n",
      "Epoch 66/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0070 - binary_accuracy: 0.9407 - val_loss: 1.0411 - val_binary_accuracy: 0.9408\n",
      "Epoch 67/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0056 - binary_accuracy: 0.9410 - val_loss: 1.0592 - val_binary_accuracy: 0.9411\n",
      "Epoch 68/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0128 - binary_accuracy: 0.9413 - val_loss: 1.0427 - val_binary_accuracy: 0.9414\n",
      "Epoch 69/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0128 - binary_accuracy: 0.9416 - val_loss: 1.0500 - val_binary_accuracy: 0.9417\n",
      "Epoch 70/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0117 - binary_accuracy: 0.9418 - val_loss: 1.0970 - val_binary_accuracy: 0.9419\n",
      "Epoch 71/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0093 - binary_accuracy: 0.9421 - val_loss: 1.0815 - val_binary_accuracy: 0.9421\n",
      "Epoch 72/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0078 - binary_accuracy: 0.9423 - val_loss: 1.0994 - val_binary_accuracy: 0.9424\n",
      "Epoch 73/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0116 - binary_accuracy: 0.9426 - val_loss: 1.0902 - val_binary_accuracy: 0.9426\n",
      "Epoch 74/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0102 - binary_accuracy: 0.9428 - val_loss: 1.1898 - val_binary_accuracy: 0.9428\n",
      "Epoch 75/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0099 - binary_accuracy: 0.9430 - val_loss: 1.1954 - val_binary_accuracy: 0.9430\n",
      "Epoch 76/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0119 - binary_accuracy: 0.9431 - val_loss: 1.2125 - val_binary_accuracy: 0.9432\n",
      "Epoch 77/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0128 - binary_accuracy: 0.9433 - val_loss: 1.2048 - val_binary_accuracy: 0.9433\n",
      "Epoch 78/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0068 - binary_accuracy: 0.9435 - val_loss: 1.1809 - val_binary_accuracy: 0.9435\n",
      "Epoch 79/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0072 - binary_accuracy: 0.9437 - val_loss: 1.1981 - val_binary_accuracy: 0.9437\n",
      "Epoch 80/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0112 - binary_accuracy: 0.9439 - val_loss: 1.2058 - val_binary_accuracy: 0.9439\n",
      "Epoch 81/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0068 - binary_accuracy: 0.9440 - val_loss: 1.2331 - val_binary_accuracy: 0.9441\n",
      "Epoch 82/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0105 - binary_accuracy: 0.9442 - val_loss: 1.2276 - val_binary_accuracy: 0.9442\n",
      "Epoch 83/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0069 - binary_accuracy: 0.9443 - val_loss: 1.2412 - val_binary_accuracy: 0.9443\n",
      "Epoch 84/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0067 - binary_accuracy: 0.9445 - val_loss: 1.2790 - val_binary_accuracy: 0.9445\n",
      "Epoch 85/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0074 - binary_accuracy: 0.9447 - val_loss: 1.1810 - val_binary_accuracy: 0.9447\n",
      "Epoch 86/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0088 - binary_accuracy: 0.9448 - val_loss: 1.1727 - val_binary_accuracy: 0.9449\n",
      "Epoch 87/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0076 - binary_accuracy: 0.9450 - val_loss: 1.1518 - val_binary_accuracy: 0.9450\n",
      "Epoch 88/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0069 - binary_accuracy: 0.9452 - val_loss: 1.1417 - val_binary_accuracy: 0.9452\n",
      "Epoch 89/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0095 - binary_accuracy: 0.9454 - val_loss: 1.2516 - val_binary_accuracy: 0.9454\n",
      "Epoch 90/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0077 - binary_accuracy: 0.9456 - val_loss: 1.2289 - val_binary_accuracy: 0.9456\n",
      "Epoch 91/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0075 - binary_accuracy: 0.9457 - val_loss: 1.2200 - val_binary_accuracy: 0.9457\n",
      "Epoch 92/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0086 - binary_accuracy: 0.9459 - val_loss: 1.2893 - val_binary_accuracy: 0.9459\n",
      "Epoch 93/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0052 - binary_accuracy: 0.9460 - val_loss: 1.2662 - val_binary_accuracy: 0.9460\n",
      "Epoch 94/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0075 - binary_accuracy: 0.9461 - val_loss: 1.2739 - val_binary_accuracy: 0.9461\n",
      "Epoch 95/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0089 - binary_accuracy: 0.9462 - val_loss: 1.2436 - val_binary_accuracy: 0.9462\n",
      "Epoch 96/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0050 - binary_accuracy: 0.9463 - val_loss: 1.2627 - val_binary_accuracy: 0.9463\n",
      "Epoch 97/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0066 - binary_accuracy: 0.9464 - val_loss: 1.3118 - val_binary_accuracy: 0.9464\n",
      "Epoch 98/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0078 - binary_accuracy: 0.9465 - val_loss: 1.3036 - val_binary_accuracy: 0.9465\n",
      "Epoch 99/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0057 - binary_accuracy: 0.9467 - val_loss: 1.2994 - val_binary_accuracy: 0.9467\n",
      "Epoch 100/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0081 - binary_accuracy: 0.9468 - val_loss: 1.3188 - val_binary_accuracy: 0.9468\n",
      "Epoch 101/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0047 - binary_accuracy: 0.9469 - val_loss: 1.3096 - val_binary_accuracy: 0.9469\n",
      "Epoch 102/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0089 - binary_accuracy: 0.9470 - val_loss: 1.2349 - val_binary_accuracy: 0.9470\n",
      "Epoch 103/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0089 - binary_accuracy: 0.9471 - val_loss: 1.2293 - val_binary_accuracy: 0.9471\n",
      "Epoch 104/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0048 - binary_accuracy: 0.9472 - val_loss: 1.3000 - val_binary_accuracy: 0.9472\n",
      "Epoch 105/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0046 - binary_accuracy: 0.9473 - val_loss: 1.2496 - val_binary_accuracy: 0.9474\n",
      "Epoch 106/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0062 - binary_accuracy: 0.9475 - val_loss: 1.2901 - val_binary_accuracy: 0.9475\n",
      "Epoch 107/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0114 - binary_accuracy: 0.9476 - val_loss: 1.2602 - val_binary_accuracy: 0.9476\n",
      "Epoch 108/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0062 - binary_accuracy: 0.9477 - val_loss: 1.2173 - val_binary_accuracy: 0.9477\n",
      "Epoch 109/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0071 - binary_accuracy: 0.9478 - val_loss: 1.2451 - val_binary_accuracy: 0.9478\n",
      "Epoch 110/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0039 - binary_accuracy: 0.9479 - val_loss: 1.2285 - val_binary_accuracy: 0.9479\n",
      "Epoch 111/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0058 - binary_accuracy: 0.9480 - val_loss: 1.2553 - val_binary_accuracy: 0.9480\n",
      "Epoch 112/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0047 - binary_accuracy: 0.9481 - val_loss: 1.2538 - val_binary_accuracy: 0.9481\n",
      "Epoch 113/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0056 - binary_accuracy: 0.9482 - val_loss: 1.2893 - val_binary_accuracy: 0.9483\n",
      "Epoch 114/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0061 - binary_accuracy: 0.9484 - val_loss: 1.3057 - val_binary_accuracy: 0.9484\n",
      "Epoch 115/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0060 - binary_accuracy: 0.9484 - val_loss: 1.2781 - val_binary_accuracy: 0.9485\n",
      "Epoch 116/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0034 - binary_accuracy: 0.9486 - val_loss: 1.3219 - val_binary_accuracy: 0.9486\n",
      "Epoch 117/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0034 - binary_accuracy: 0.9487 - val_loss: 1.3188 - val_binary_accuracy: 0.9487\n",
      "Epoch 118/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0051 - binary_accuracy: 0.9487 - val_loss: 1.3072 - val_binary_accuracy: 0.9487\n",
      "Epoch 119/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0078 - binary_accuracy: 0.9488 - val_loss: 1.2776 - val_binary_accuracy: 0.9488\n",
      "Epoch 120/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0102 - binary_accuracy: 0.9489 - val_loss: 1.2957 - val_binary_accuracy: 0.9489\n",
      "Epoch 121/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0053 - binary_accuracy: 0.9490 - val_loss: 1.3116 - val_binary_accuracy: 0.9490\n",
      "Epoch 122/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0072 - binary_accuracy: 0.9491 - val_loss: 1.2894 - val_binary_accuracy: 0.9491\n",
      "Epoch 123/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0056 - binary_accuracy: 0.9491 - val_loss: 1.2913 - val_binary_accuracy: 0.9491\n",
      "Epoch 124/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0058 - binary_accuracy: 0.9492 - val_loss: 1.2467 - val_binary_accuracy: 0.9492\n",
      "Epoch 125/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0099 - binary_accuracy: 0.9492 - val_loss: 1.1832 - val_binary_accuracy: 0.9492\n",
      "Epoch 126/150\n",
      "1980/1980 [==============================] - 42s 21ms/step - loss: 0.0051 - binary_accuracy: 0.9493 - val_loss: 1.2558 - val_binary_accuracy: 0.9493\n",
      "Epoch 127/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0042 - binary_accuracy: 0.9494 - val_loss: 1.2575 - val_binary_accuracy: 0.9494\n",
      "Epoch 128/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0042 - binary_accuracy: 0.9494 - val_loss: 1.2033 - val_binary_accuracy: 0.9494\n",
      "Epoch 129/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0053 - binary_accuracy: 0.9495 - val_loss: 1.2301 - val_binary_accuracy: 0.9495\n",
      "Epoch 130/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0049 - binary_accuracy: 0.9496 - val_loss: 1.2200 - val_binary_accuracy: 0.9496\n",
      "Epoch 131/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0051 - binary_accuracy: 0.9496 - val_loss: 1.2348 - val_binary_accuracy: 0.9497\n",
      "Epoch 132/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0073 - binary_accuracy: 0.9497 - val_loss: 1.2237 - val_binary_accuracy: 0.9497\n",
      "Epoch 133/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0072 - binary_accuracy: 0.9498 - val_loss: 1.2324 - val_binary_accuracy: 0.9498\n",
      "Epoch 134/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0072 - binary_accuracy: 0.9499 - val_loss: 1.4218 - val_binary_accuracy: 0.9499\n",
      "Epoch 135/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0059 - binary_accuracy: 0.9500 - val_loss: 1.3512 - val_binary_accuracy: 0.9500\n",
      "Epoch 136/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0106 - binary_accuracy: 0.9501 - val_loss: 1.3581 - val_binary_accuracy: 0.9500\n",
      "Epoch 137/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0037 - binary_accuracy: 0.9501 - val_loss: 1.3708 - val_binary_accuracy: 0.9501\n",
      "Epoch 138/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0064 - binary_accuracy: 0.9502 - val_loss: 1.4318 - val_binary_accuracy: 0.9502\n",
      "Epoch 139/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0041 - binary_accuracy: 0.9502 - val_loss: 1.4130 - val_binary_accuracy: 0.9502\n",
      "Epoch 140/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0028 - binary_accuracy: 0.9503 - val_loss: 1.4916 - val_binary_accuracy: 0.9503\n",
      "Epoch 141/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0058 - binary_accuracy: 0.9504 - val_loss: 1.3708 - val_binary_accuracy: 0.9504\n",
      "Epoch 142/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0041 - binary_accuracy: 0.9504 - val_loss: 1.3829 - val_binary_accuracy: 0.9505\n",
      "Epoch 143/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0098 - binary_accuracy: 0.9505 - val_loss: 1.3474 - val_binary_accuracy: 0.9505\n",
      "Epoch 144/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0035 - binary_accuracy: 0.9506 - val_loss: 1.3332 - val_binary_accuracy: 0.9506\n",
      "Epoch 145/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0054 - binary_accuracy: 0.9507 - val_loss: 1.3446 - val_binary_accuracy: 0.9506\n",
      "Epoch 146/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0083 - binary_accuracy: 0.9507 - val_loss: 1.3410 - val_binary_accuracy: 0.9507\n",
      "Epoch 147/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0048 - binary_accuracy: 0.9508 - val_loss: 1.3723 - val_binary_accuracy: 0.9508\n",
      "Epoch 148/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0042 - binary_accuracy: 0.9508 - val_loss: 1.3061 - val_binary_accuracy: 0.9508\n",
      "Epoch 149/150\n",
      "1980/1980 [==============================] - 40s 20ms/step - loss: 0.0041 - binary_accuracy: 0.9509 - val_loss: 1.3529 - val_binary_accuracy: 0.9509\n",
      "Epoch 150/150\n",
      "1980/1980 [==============================] - 39s 20ms/step - loss: 0.0051 - binary_accuracy: 0.9509 - val_loss: 1.3105 - val_binary_accuracy: 0.9509\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x = [inputA, inputB], y = y, epochs = 150, callbacks = [checkpoint_cb], validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "def plot_history(history):\n",
    "    pd.DataFrame(history.history).plot()\n",
    "    \n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 224, 224, 3)\n",
      "(1000, 224, 224, 3)\n",
      "(1000, 1)\n"
     ]
    }
   ],
   "source": [
    "inputA, inputB, y = load_data(r'C:\\Users\\Dev\\Desktop\\Ongoing_projects\\Face_Recognition\\Data\\pairsDevTest.txt')\n",
    "print(inputA.shape)\n",
    "print(inputB.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 19s 19ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57.265838256835934, 0.9502257108688354]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x = [inputA, inputB], y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfgpu",
   "language": "python",
   "name": "tfgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
